{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import openpyxl\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "from statistics import mean\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import root\n",
    "from scipy.stats import chi2, norm, nct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rgamma\n",
    "Calculate the approxomation of the ratio of gamma(n+1)/gamma(n+3/2) for large m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rgamma(n):\n",
    "    x = n + 1\n",
    "    fval = np.sqrt(x-.25) * (1 + 1 / (64 * x * x) + 1 / (128 * x * x * x))\n",
    "    return 1/fval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ncd_cdf\n",
    "Calculate the cdf of a non-central t statistic\n",
    "t is the cdf variable; n is # degrees of freedom; δ is the noncentrality parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "import scipy\n",
    "\n",
    "def nct_cdf(t, n, delta, tol):\n",
    "    r = lambda t_val, n_val: t_val*t_val/(t_val*t_val+n_val)\n",
    "    if (t >= 0):\n",
    "        out = stats.norm.cdf(-delta)\n",
    "        for m in range(0, 1000):\n",
    "            if (m <= 50):\n",
    "                sumincr = 0.5 * stats.poisson.pmf(m, delta * delta / 2) * (stats.beta.cdf(r(t, n), m + 0.5, n / 2) + ((delta * scipy.special.gamma(m + 1)) / (np.sqrt(2) * scipy.special.gamma(m + 1.5))) * stats.beta.cdf(r(t, n), m + 1, n / 2))\n",
    "            else:\n",
    "                sumincr = 0.5 * stats.poisson.pmf(m, delta * delta / 2) * (stats.beta.cdf(r(t, n), m + 0.5, n / 2) + (delta / np.sqrt(2) * rgamma(m)) * stats.beta.cdf(r(t, n), m + 1, n / 2))\n",
    "            out = out + sumincr\n",
    "\n",
    "            if (sumincr / out < tol):\n",
    "                break\n",
    "    else:\n",
    "        out = stats.norm.cdf(delta)\n",
    "        for m in range(0, 1000):\n",
    "            if (m <= 50):\n",
    "                sumincr = 0.5 * stats.poisson.pmf(m, delta * delta / 2) * (stats.beta.cdf(r(t, n), m + 0.5, n / 2) + ((delta * scipy.special.gamma(m + 1)) / (np.sqrt(2) * scipy.special.gamma(m + 1.5))) * stats.beta.cdf(r(t, n), m + 1, n / 2))\n",
    "            else:\n",
    "                sumincr = 0.5 * stats.poisson.pmf(m, delta * delta / 2) * (stats.beta.cdf(r(t, n), m + 0.5, n / 2) + (delta / np.sqrt(2) * rgamma(m)) * stats.beta.cdf(r(t, n), m + 1, n / 2))\n",
    "\n",
    "            out = out + sumincr\n",
    "            if (abs(sumincr)/out < tol):\n",
    "                out = 1 - out\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inv_nct_cdf\n",
    "Inverse of non-central t-statistic cdf; finds the threshold yielding a cdf value of P\n",
    "\n",
    "n is the # of degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_nct_cdf(P, n, delta, tol):\n",
    "\n",
    "    # set initial t guess to lowercase delta (delta) and step up and down to find an interval where f(t) has opposite signs for the endpoints\n",
    "    f = lambda t: nct_cdf(t, n, delta, tol) - P\n",
    "\n",
    "    x0 = delta\n",
    "\n",
    "    # Determine the direction to move in\n",
    "    if f(x0) <= 0:\n",
    "        x1 = 2 * delta\n",
    "        while (f(x0) <= 0 and f(x1) <= 0):\n",
    "            x0 = x1\n",
    "            x1 = x1 + delta\n",
    "    else:\n",
    "        x0 = 0\n",
    "        x1 = delta\n",
    "        while (f(x0) > 0 and f(x1) >= 0):\n",
    "            x1 = x0\n",
    "            x0 = x0 - delta\n",
    "    \n",
    "\n",
    "    return opt.brentq(f, x0, x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ktol\n",
    "Find one-sided tolerance interval k (multiple of sample std dev away from sample mean), given γ, α and n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def ktol(upsilon, a, n, tol):\n",
    "    zp = stats.norm.ppf(1-upsilon, 0, 1)\n",
    "    delta = math.sqrt(n) * zp\n",
    "    result = inv_nct_cdf(1 - a, n - 1, delta, tol) / math.sqrt(n)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# round_above_threshold\n",
    "A function for helping with imprecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_above_threshold(n):\n",
    "    if n - int(n) >= 0.98: \n",
    "        return round(n)\n",
    "    else: \n",
    "        return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trap\n",
    "Trapezoid of height ht, left base lb, left top lt, right top rt, right base rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trap(x, ht, lb, lt, rt, rb):\n",
    "    global tr\n",
    "    if x < lb:\n",
    "        return 0\n",
    "    if x > rb:\n",
    "        return 0\n",
    "    if lt <= x <= rt:\n",
    "        return ht\n",
    "    if lb <= x < lt:\n",
    "        tr = ht * (x - lb) / (lt - lb)\n",
    "    if rt < x <= rb:\n",
    "        tr = ht * (rb - x) / (rb - rt)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bad_data\n",
    "eliminates invalid intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_data(x, x0, x1):\n",
    "    y = None\n",
    "    x = np.array(x)\n",
    "    a = x[:, 0]\n",
    "    b = x[:, 1]\n",
    "    for i in range(0, len(x)):\n",
    "        # remove rows with infeasible endpoints\n",
    "        if ((x0 <= a[i] < b[i] <= x1) and (b[i] - a[i] < x1 - x0)):\n",
    "            if y is None:\n",
    "                y = [[a[i], b[i]]]\n",
    "            else:\n",
    "                y.append([a[i], b[i]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# box_and_whisker\n",
    "calculate quartiles and inter-quartile ranges on right or left interval endpoints\n",
    "\n",
    "x is an n-vector of right or left interval endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_and_whisker(x):\n",
    "    # calculate quartile index\n",
    "    global q75, q25\n",
    "    nq = np.floor(len(x) / 4)\n",
    "\n",
    "    # skip this test if nq = 0\n",
    "    if (nq == 0):\n",
    "        return x\n",
    "\n",
    "    # find first and third quartile values\n",
    "    remainder = np.mod(len(x), 4)\n",
    "    y = np.sort(x)\n",
    "    if (remainder == 0):\n",
    "        q25 = (y[int(nq)] + y[int(nq) - 1]) / 2\n",
    "        q75 = (y[int(3 * nq)] + y[int(3 * nq) - 1]) / 2\n",
    "    elif (remainder == 1):\n",
    "        q25 = (y[int(nq)] + y[int(nq) - 1]) / 2\n",
    "        q75 = (y[int(3 * nq)] + y[int(3 * nq + 1)]) / 2\n",
    "    elif (remainder == 2):\n",
    "        q25 = y[int(nq)]\n",
    "        q75 = y[int(3 * nq + 1)]\n",
    "    elif (remainder == 3):\n",
    "        q25 = y[int(nq)]\n",
    "        q75 = y[int(3 * nq + 2)]\n",
    "\n",
    "    # find inner quartile range and bounds of valid endpoints\n",
    "    iqr = q75 - q25\n",
    "    xmin = q25 - 1.5 * iqr\n",
    "    xmax = q75 + 1.5 * iqr\n",
    "    return [xmin, xmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outlier_test\n",
    "flags outlier endpoints\n",
    "\n",
    "x is an n x 2 vector of right and left interval endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_test(x):\n",
    "    # calculate box and whisker test on x[0] and x[1]\n",
    "    x = np.array(x)\n",
    "    x0 = box_and_whisker(x[:, 0])\n",
    "    x1 = box_and_whisker(x[:, 1])\n",
    "    y = []\n",
    "\n",
    "    # eliminate outlier endpoints in x using box and whisker test\n",
    "    for i in range(0, len(x)):\n",
    "        if (x0[0] <= x[i, 0] <= x0[1] and x1[0] <= x[i, 1] <= x1[1]):\n",
    "            y.append(x[i])\n",
    "    if len(y) == 0:\n",
    "        return None\n",
    "\n",
    "    y = np.array(y)\n",
    "    # y has first pass outliers eliminated\n",
    "    # repeat box and whisker test on L=y[1]-y[0]\n",
    "    L = y[:, 1] - y[:, 0]\n",
    "    Lbw = box_and_whisker(L)\n",
    "    z = []\n",
    "    for i in range(0, len(y)):\n",
    "        if (Lbw[0] <= L[i] <= Lbw[1]):\n",
    "            z.append(y[i])\n",
    "    if len(z) == 0:\n",
    "        return None\n",
    "    return np.array(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fr\n",
    "Root function for Eq. A. 18 of reference [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fr(y, a):\n",
    "    r = y\n",
    "    func = lambda r: norm.cdf(y + r) - norm.cdf(y - r) - (1 - a)\n",
    "    return root(func, r).x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fk\n",
    "Q(lambda, k) function for Eq. A. 19 of reference [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fk(xk, a, n):\n",
    "    def integrand(y):\n",
    "        term1 = ((n - 1) * fr(y, a) ** 2) / (xk ** 2)\n",
    "        term2 = n - 1\n",
    "        pchisq = 1 - chi2.cdf(term1, term2)\n",
    "        term3 = (-1 / 2) * n * y ** 2\n",
    "        return ((2 * np.sqrt(n)) / (np.sqrt(2 * np.pi))) * pchisq * np.exp(term3)\n",
    "\n",
    "    result, error = quad(integrand, 0, np.inf)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kk\n",
    "Solve for k of Eq. A. 14 of reference [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kk(a, y, n):\n",
    "    xk = 2\n",
    "    func = lambda xk: fk(xk, a, n) - (1 - y)\n",
    "    return root(func, xk).x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tolerance\n",
    "flags valuews of x where either endpoint is outside the tolerance limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolerance(x, m, sigma, k):\n",
    "    upperlim = m + k * sigma\n",
    "    lowerlim = m - k * sigma\n",
    "    for i in range(len(x)):\n",
    "        if lowerlim <= x[i] <= upperlim:\n",
    "            continue\n",
    "        else:\n",
    "            x[i] = -1000\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reasonable\n",
    "eliminate unreasonable intervals that do not overlap all other intervals or have too little overlap\n",
    "x is an n x 2 vector of intervals\n",
    "ml, mr, sigma_l, sigma_r are means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasonable(x, ml, mr, sigma_l, sigma_r):\n",
    "    # If sigma_l or sigma_r is zero, all intervals overlap by definition\n",
    "    if sigma_l == 0 or sigma_r == 0:\n",
    "        return x\n",
    "    # If sigma)l == sigma_r, the solution to Eq. (A-6) in Ref. [1] is the mean of the means\n",
    "    if sigma_l == sigma_r:\n",
    "        zeta = (ml + mr) / 2\n",
    "    else:\n",
    "        zeta_1 = ((mr * sigma_l ** 2 - ml * sigma_r ** 2) - sigma_l * sigma_r * np.sqrt(\n",
    "            (ml - mr) ** 2 + 2 * (sigma_l ** 2 - sigma_r ** 2) * math.log(sigma_l / sigma_r))) / (\n",
    "                             sigma_l ** 2 - sigma_r ** 2)\n",
    "        zeta_2 = ((mr * sigma_l ** 2 - ml * sigma_r ** 2) + sigma_l * sigma_r * np.sqrt(\n",
    "            (ml - mr) ** 2 + 2 * (sigma_l ** 2 - sigma_r ** 2) * math.log(sigma_l / sigma_r))) / (\n",
    "                             sigma_l ** 2 - sigma_r ** 2)\n",
    "\n",
    "        if ml <= zeta_1 <= mr:\n",
    "            zeta = zeta_1\n",
    "        else:\n",
    "            zeta = zeta_2\n",
    "\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        # maybe the one line I am not proud of, because of how python handles floating point numbers, it is necessary to round the final value\n",
    "        if (2 * ml - zeta <= x[i][0] < zeta < x[i][1] <= round_above_threshold(2 * mr - zeta)):\n",
    "            y.append(x[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataclean helper functions\n",
    "Stage 1 -- Bad data elimination\n",
    "\n",
    "Stage 2 -- Outlier elimination\n",
    "\n",
    "Stage 3 -- Tolerance limit processing\n",
    "\n",
    "Stage 4 -- Reasonable interval processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_bad_data(x, x0, x1):\n",
    "    y = bad_data(x, x0, x1)\n",
    "    if y is None:\n",
    "        return None, \"All intervals eliminated at bad data stage\"\n",
    "    return y, None\n",
    "\n",
    "def eliminate_outliers(y):\n",
    "    z = outlier_test(y)\n",
    "    if z is None:\n",
    "        return None, \"All intervals eliminated at outlier elimination stage\"\n",
    "    return z, None\n",
    "\n",
    "def calculate_mean_std(z):\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_left = np.mean(z[:, 0])\n",
    "    std_left = statistics.stdev(z[:, 0])\n",
    "    mean_right = np.mean(z[:, 1])\n",
    "    std_right = statistics.stdev(z[:, 1])\n",
    "    return mean_left, std_left, mean_right, std_right\n",
    "\n",
    "\n",
    "def tolerance_limit_processing(z, mean_left, std_left, mean_right, std_right, a, significance_level):\n",
    "    tolerance_factor = kk(a, significance_level, len(z) + 1)\n",
    "    y0 = tolerance(z[:, 0], mean_left, std_left, tolerance_factor)\n",
    "    y1 = tolerance(z[:, 1], mean_right, std_right, tolerance_factor)\n",
    "    z = []\n",
    "\n",
    "    for i in range(len(y0)):\n",
    "        if int(y0[i]) != -1000 and int(y1[i]) != -1000:\n",
    "            z.append([y0[i], y1[i]])\n",
    "\n",
    "    if z:\n",
    "        return np.array(z), None\n",
    "    else:\n",
    "        return np.empty((0, 2)), \"All intervals eliminated at tolerance limit processing stage\"\n",
    "\n",
    "\n",
    "def reasonable_interval_processing(z, mean_left, std_left, mean_right, std_right):\n",
    "    z = reasonable(z.tolist(), mean_left, mean_right, std_left, std_right)\n",
    "    if z:\n",
    "        return np.array(z), None\n",
    "    else:\n",
    "        return np.empty((0, 2)), \"All intervals eliminated at reasonable interval processing stage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataclean\n",
    "Preprocess raw interval data for a given word to eliminate unacceptable intervals using all of the above tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataclean(x, x0, x1, a, significance_level):\n",
    "    y = bad_data(x, x0, x1)\n",
    "    if y is None:\n",
    "        return \"All intervals eliminated at bad data stage\"\n",
    "\n",
    "    z, message = eliminate_outliers(y)\n",
    "    if message:\n",
    "        return message\n",
    "\n",
    "    mean_left, std_left, mean_right, std_right = calculate_mean_std(z)\n",
    "\n",
    "    z, message = tolerance_limit_processing(z, mean_left, std_left, mean_right, std_right, a, significance_level)\n",
    "    if message:\n",
    "        return message\n",
    "\n",
    "    z, message = reasonable_interval_processing(z, mean_left, std_left, mean_right, std_right)\n",
    "    if message:\n",
    "        return message\n",
    "\n",
    "    out = [[], [], []]\n",
    "    out[0] = z\n",
    "    # Compute sample means of residual interval endpoints\n",
    "    out[1] = np.mean(z[:, 0])\n",
    "    out[2] = np.mean(z[:, 1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_fou_class0\n",
    "Step 1 of HMA: determine the FOU class for naturally bounded (class 0) sets\n",
    "\n",
    "x is an n x 2 array of intervals that survived the dataclean process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_fou_class0(x, x0, x1):\n",
    "    # [x0, x1] is the bound interval\n",
    "    ml = np.mean(x[:, 0])\n",
    "    sigma_l = statistics.stdev(x[:, 0])\n",
    "    mr = np.mean(x[:, 1])\n",
    "    sigma_r = statistics.stdev(x[:, 1])\n",
    "    k = nct_cdf.ktol(0.05, 0.05, len(x), 10 ** -5)\n",
    "    al = ml - k * sigma_l\n",
    "    bu = mr + k * sigma_r\n",
    "    if al <= x0:\n",
    "        out = \"Left shoulder FOU\"\n",
    "    else:\n",
    "        if bu >= x1:\n",
    "            out = \"Right shoulder FOU\"\n",
    "        else:\n",
    "            out = \"Interior FOU\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_fou_class1\n",
    "Step 1 of HMA: determine the FOU class for sets bounded only on the left (class 1)\n",
    "\n",
    "In these cases, there are only Left shoulder or Interior FOUs\n",
    "\n",
    "x is an n x 2 array of intervals that survived the dataclean processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_fou_class1(x, x0):\n",
    "    # x0 is the left bound (typically 0) for the intervals\n",
    "    ml = np.mean(x[:, 0])\n",
    "    sigma_l = statistics.stdev(x[:, 0])\n",
    "    k = nct_cdf.ktol(0.05, 0.05, len(x), 10 ** -5)\n",
    "    al = ml - k * sigma_l\n",
    "    if al <= x0:\n",
    "        out = \"Left shoulder FOU\"\n",
    "    else:\n",
    "        out = \"Interior FOU\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_overlap\n",
    "Compute overlap interval of x rows for FOU class c\n",
    "\n",
    "Note: the data part eliminates non-overlapping intervals, so we are assured of overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_overlap(x, c, x0, x1):\n",
    "    if c == \"Left shoulder FOU\":\n",
    "        out = [x0, min(x[:, 1])]\n",
    "    elif c == \"Interior FOU\":\n",
    "        out = [max(x[:, 0]), min(x[:, 1])]\n",
    "    elif c == \"Right shoulder FOU\":\n",
    "        out = [max(x[:, 0]), x1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_olap_remove\n",
    "Given interval array x and FOU class, remove overlap from original intervals\n",
    "\n",
    "For Left or Right shoulder FOUs, this leaves a single array of smaller intervals\n",
    "\n",
    "For Interior FOUs, this leaves a nested 2-vector of arrays of smaller intervals for the left/right sections of the FOU, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_olap_remove(x, c):\n",
    "    out = []\n",
    "    if c == \"Left shoulder FOU\":\n",
    "        bmin = min(x[:, 1])\n",
    "        for i in range(len(x)):\n",
    "            out.append([bmin, x[i, 1]])\n",
    "    elif c == \"Right shoulder FOU\":\n",
    "        amax = max(x[:, 0])\n",
    "        for i in range(len(x)):\n",
    "            out.append([x[i, 0], amax])\n",
    "    elif c == \"Interior FOU\":\n",
    "        out0 = []\n",
    "        out1 = []\n",
    "        amax = max(x[:, 0])\n",
    "        bmin = min(x[:, 1])\n",
    "        for i in range(len(x)):\n",
    "            out0.append([x[i, 0], amax])\n",
    "            out1.append([bmin, x[i, 1]])\n",
    "        out = [out0, out1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aleft\n",
    "Calculate a parameters for left-hand side of Interior or Right shoulder FOU\n",
    "\n",
    "See eq. (5) in HMA paper\n",
    "\n",
    "xr is the set of reduced intervals for the left-hand side from the hmaolapremove function\n",
    "    \n",
    "x0 is the left bound\n",
    "    \n",
    "oleft is the left bound of the overlap interval of the original interval set\n",
    "    \n",
    "Thus, oleft will be the max right bound of the reduced intervals xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aleft(xr, x0):\n",
    "    xr = np.array(xr)\n",
    "    oleft = max(xr[:, 0])\n",
    "    intlengths = np.abs(xr[:, 0] - oleft)\n",
    "    # mLH is the mean of interval lengths wrt the left bound of the overlap interval (oleft)\n",
    "    mLH = oleft - np.mean(intlengths)\n",
    "    sLH = statistics.stdev(intlengths)\n",
    "    a_left = max(x0, oleft - 3 * np.sqrt(2) * sLH)\n",
    "    a_right = min(oleft, 6 * mLH + 3 * np.sqrt(2) * sLH - 5 * oleft)\n",
    "    # Now test to if the order is sensible, and if not, reverse them\n",
    "    if a_left <= a_right:\n",
    "        out = [a_left, a_right]\n",
    "    else:\n",
    "        out = [max(x0, a_right), min(oleft, a_left)]\n",
    "    # out_0/out_1 are the UMF/LMF intersections with the x-axis, respectively\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aright\n",
    "Calculate a parameters for right-hand side of Interior or Left shoulder FOU\n",
    "\n",
    "See eq. (6) in HMA paper\n",
    "\n",
    "xr is the set of reduced intervals for the right-hand side from the hmaolapremove function\n",
    "\n",
    "x1 is the right bound\n",
    "\n",
    "oright is the right bound of the overlap interval of the original interval set\n",
    "\n",
    "Thus, oright will be the min left bound of the reduced intervals xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aright(xr, x1):\n",
    "    xr = np.array(xr)\n",
    "    oright = min(xr[:, 1])\n",
    "    intlengths = np.abs(xr[:, 1] - oright)\n",
    "    #mRH is the mean of interval length wrt the right bound of the overlap interval (oright)\n",
    "    mRH = oright + np.mean(intlengths)\n",
    "    sRH = statistics.stdev(intlengths)\n",
    "    b_right = min(x1, oright + 3 * np.sqrt(2) * sRH)\n",
    "    b_left = max(oright, 6 * mRH - 3 * np.sqrt(2) * sRH - 5 * oright)\n",
    "    # Now test to if the order is sensible, and if not, reverse them\n",
    "    if b_left <= b_right:\n",
    "        out = [b_left, b_right]\n",
    "    else:\n",
    "        out = [max(oright, b_right), min(x1, b_left)]\n",
    "    # out_0/out_1 are the UMF/LMF intersections with the x-axis, respectively\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_map\n",
    "Implement the mapping of fuzzy part step 4\n",
    "\n",
    "x is the set of reduced intervals from the hmaolapremove function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_map(x, c, x0, x1):\n",
    "    \"\"\"Implement the mapping of fuzzy part step 4\n",
    "    x is the set of reduced intervals from the hmaolapremove function\"\"\"\n",
    "    if c == \"Interior FOU\":\n",
    "        out = [aleft(x[0], x0), aright(x[1], x1)]\n",
    "    elif c == \"Left shoulder FOU\":\n",
    "        out = [aright(x, x1)]\n",
    "    elif c == \"Right shoulder FOU\":\n",
    "        out = [aleft(x, x0)]\n",
    "        # out will be a single 2-vector for left or right-shoulder FOU, a nested 2-vector of 2-vectors for interior FOUs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma_trap\n",
    "Go from an array of intervals x to the UMF/LMF trapezoidal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hma_trap(x, x0, x1):\n",
    "    # Go from an array of intervals x to the UMF/LMF trapezoidal parameters\n",
    "    c = hma_fou_class0(x, x0, x1)\n",
    "    # compute overlap interval\n",
    "    olap_interval = hma_overlap(x, c, x0, x1)\n",
    "    # compute reduced intervals with overlap removed\n",
    "    x_reduced = hma_olap_remove(x, c)\n",
    "    # compute the trapezoidal parameters\n",
    "    tp = hma_map(x_reduced, c, x0, x1)\n",
    "    # calculate trapezoid parameters for different FOUs\n",
    "    if c == \"Interior FOU\":\n",
    "        # tp is a nested 2-vector of 2-vectors for left/right UMF/LMF x-axis intercepts\n",
    "        out_UMF = [tp[0][0], olap_interval[0], olap_interval[1], tp[1][1]]\n",
    "        out_LMF = [tp[0][1], olap_interval[0], olap_interval[1], tp[1][0]] \n",
    "    elif c == \"Left shoulder FOU\":\n",
    "        # tp is a 2-vector of UMF/LMF x-axis intercepts\n",
    "        out_UMF = [x0, x0, olap_interval[1], tp[0][1]]\n",
    "        out_LMF = [x0, x0, olap_interval[1], tp[0][0]]\n",
    "    elif c == \"Right shoulder FOU\":\n",
    "        # tp is a 2-vector of UMF/LMF x-axis intercepts\n",
    "        out_UMF = [tp[0][0], olap_interval[0], x1, x1]\n",
    "        out_LMF = [tp[0][1], olap_interval[0], x1, x1]\n",
    "    return [out_UMF, out_LMF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trap_z\n",
    "Trapzoidal function with h parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trap_z(x, h):\n",
    "    \"\"\"Trapzoidal function with h parameters\"\"\"\n",
    "    return [noncenteral_tstatic_cdf.trapz(x, 1, h[0][0], h[1][0], h[2][0], h[3][0]), noncenteral_tstatic_cdf.trapz(x, 1, h[0][1], h[1][1], h[2][1], h[3][1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
